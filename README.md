# ğŸ§± Kit Fundador v2.0

Un starter kit **agnÃ³stico de lenguaje**, diseÃ±ado para iniciar proyectos de software con **Clean Architecture, DDD, TDD y mejores prÃ¡cticas**, tanto para equipos humanos como para agentes IA.

Este repositorio proporciona el **esqueleto profesional mÃ­nimo** para arrancar un proyecto sin deuda tÃ©cnica inicial, con una estructura clara, tests desde el dÃ­a 1 y un setup robusto que guÃ­a a desarrolladores y agentes hacia decisiones correctas.

- âœ… **TypeScript** (Node.js + Express + Jest + Prisma)
- âœ… **Python** (FastAPI + Pytest + SQLAlchemy)
- âœ… **JSON/Config** (para cualquier otro lenguaje)

## ğŸ§© Decisiones del stack base

- El perfil predeterminado del starkit usa **TypeScript + Node.js 20** con Express mÃ­nimo para exponer ejemplos de handlers.
- Los comandos de lint, build y testing se alinean con **ESLint + Prettier + Jest + esbuild**; tÃ³malos como referencia y reemplÃ¡zalos en cuanto cierres tu propio stack.
- Consulta [`dev-docs/user-dd/tech-stack-decisions.md`](dev-docs/user-dd/tech-stack-decisions.md) y [`config/tech-stack.json`](config/tech-stack.json) antes de proponer dependencias nuevas o sugerir frameworks alternativos.

## ğŸ¯ PropÃ³sito

## âœ¨ Â¿QuÃ© incluye este kit?

âœ”ï¸ Clean Architecture â†’ separaciÃ³n clara Domain / Application / Infrastructure
âœ”ï¸ TDD estricto: estructura de tests lista (unit, integration, e2e)
âœ”ï¸ Scripts de setup robustos (validaciones + modo interactivo)
âœ”ï¸ Observabilidad opcional (Prometheus, Grafana, Jaeger)
âœ”ï¸ Plantillas TypeScript, Python y JSON/Config
âœ”ï¸ DocumentaciÃ³n completa en `dev-docs/`
âœ”ï¸ Perfiles de ejecuciÃ³n EJECUTOR / VALIDADOR para agentes IA
âœ”ï¸ Sistema de guardrails con investigaciÃ³n acadÃ©mica (Chen et al 2024, Liu et al 2024)

> Este README es intencionalmente breve. La documentaciÃ³n extendida estÃ¡ en **[dev-docs/README_FULL.md](dev-docs/README_FULL.md)**.

---

## ğŸš€ Quick Start

```bash
git clone https://github.com/fegome90-cmd/kit_fundador.git mi-proyecto
cd mi-proyecto

chmod +x scripts/setup.sh
./scripts/setup.sh [--force]

# Selecciona el stack cuando se solicite
# Opciones disponibles:
#   1) TypeScript + Node.js (Express, Jest, Prisma)
#   2) Python (FastAPI, Pytest, SQLAlchemy)
#   3) JSON/Config only (para usar con cualquier lenguaje)
```

> ğŸ’¡ El script valida prerequisitos (`git`, `npm`, `python3`, `docker-compose`) antes de copiar archivos y te pedirÃ¡ confirmaciÃ³n si detecta contenido existente. Usa `--force` solo cuando estÃ©s seguro de sobrescribir y omitir las validaciones.

### 2. Configurar Proyecto

```
1) TypeScript + Node.js (Express + Jest + Prisma)
2) Python (FastAPI + Pytest + SQLAlchemy)
3) JSON/Config only
```

---

## ğŸ“ Estructura mÃ­nima del proyecto

# Verificar que el setup interactivo siga funcionando
npm run test:setup     # o make test:setup para usar el harness bash

# Validar arquitectura
make validate
```

## ğŸ›¡ï¸ RemediaciÃ³n del setup interactivo

El informe [`AUDITORIA_SETUP_SH.md`](document/informes_CC/AUDITORIA_SETUP_SH.md) detectÃ³ un bloqueo crÃ­tico en la opciÃ³n Python,
19 vulnerabilidades moderadas en la plantilla TypeScript y varios riesgos de usabilidad. Antes de reutilizar `scripts/setup.sh`
en un proyecto real, sigue el [plan de ejecuciÃ³n](dev-docs/setup/setup-sh-remediation-plan.md) que prioriza:

1. **Correcciones crÃ­ticas** (dependencias Python/TypeScript y manejo de errores de `pip`).
2. **Mejoras de usabilidad** (confirmaciÃ³n de sobrescritura, validaciÃ³n de prerequisitos y limpieza de templates).
3. **Hardening opcional** (tests del script, flags verbosos y guardas para `docker-compose`).

> **Estado actual**: âœ… **Fases A y B completadas**. De la **Fase C** ya estÃ¡n operativos el harness Bash (`tests/setup/setup_script.test.sh`, accesible vÃ­a `npm run test:setup`/`make test:setup`) y la integridad de metadatos (`utc_timestamp` + advertencia cuando falta `docker-compose.dev.yml`). La mejora de observabilidad (`--verbose`/`--no-color`) quedÃ³ documentada como **opcional** para que cada consumidor decida si la incorpora.

> ğŸ“¦ DespuÃ©s de cada ejecuciÃ³n, decide quÃ© hacer con `templates/` directamente desde el prompt final; si prefieres evitar preguntas en entornos automatizados, invoca el script con `--force`.

> ğŸ§ª En pipelines sin acceso a npm/PyPI puedes ejecutar `SETUP_SH_SKIP_INSTALLS=true ./scripts/setup.sh` para saltar `npm install`/`pip install` (el harness usa esa variable por defecto) y aun asÃ­ validar el resto del flujo.

Documenta quÃ© fases aplicaste en `dev-docs/task.md` antes de continuar con las tareas principales del roadmap.

## ğŸ—„ï¸ Blueprint de base de datos y migraciones

Aunque el starkit no provisiona una base de datos real, TASK-003 exige que cada equipo defina su propia estrategia de
persistencia. Consulta [`dev-docs/infrastructure/database-blueprint.md`](dev-docs/infrastructure/database-blueprint.md)
para seguir una guÃ­a agnÃ³stica que cubre:

- Servicios recomendados en `docker-compose.dev.yml` (ejemplo con Postgres, adaptable a otros motores).
- Archivos esperados (`.env.example`, `db/migrations/`, seeds) y su relaciÃ³n con `package.json`/`Makefile`.
- Minitareas, revisiones y comandos de testing que puedes usar para adaptar el kit sin aÃ±adir dependencias
  obligatorias.

Completa la checklist del blueprint y actualiza `dev-docs/task.md` cuando definas tu stack real para que el resto del
equipo conozca el estado de TASK-003.

## ğŸ§  Blueprint de casos de uso y handlers

La capa de aplicaciÃ³n permanece como plantilla hasta que cada consumidor implemente su primer flujo end-to-end.
Para evitar improvisaciones, sigue [`dev-docs/application/use-case-blueprint.md`](dev-docs/application/use-case-blueprint.md),
que describe:

- CÃ³mo seleccionar el primer caso de uso del bounded context vigente y registrar la decisiÃ³n en los docs del proyecto.
- QuÃ© artefactos crear (DTOs, puertos, handlers y stubs de repositorio/event publisher) sin romper el aislamiento del dominio.
- Minitareas de testing (unit/integration) y los puntos de code review que deben revisarse antes de dar por completada TASK-004.

Marca el avance en `dev-docs/task.md` y `dev-docs/plan.md` en cuanto adoptes el blueprint para que el resto del equipo
identifique quÃ© use case estÃ¡ en marcha y quÃ© interfaces siguen pendientes.

## ğŸ§­ Post-clone Checklist

Este repositorio es un **starkit agnÃ³stico**: incluye ejemplos, no una aplicaciÃ³n completa. DespuÃ©s de clonar, sigue estos pasos
para dejarlo operativo en tu contexto:

1. **Entry point real** â†’ crea el archivo de arranque de tu servicio (`src/index.ts`, `main.py`, etc.) y actualiza los scripts
   (`package.json`, `Makefile`, `docker-compose`) para apuntar a Ã©l.
2. **Dependencias implÃ­citas** â†’ importa manualmente mÃ³dulos como `crypto` y reemplaza los helpers ficticios (`hashed_${plainPassword}`,
   event dispatcher en memoria) por servicios reales.
3. **Tooling** â†’ decide tu stack de lint/test (ESLint, Pytest, Go test, etc.) y actualiza `lint-staged`, hooks y pipelines segÃºn
   corresponda. Consulta la [GuÃ­a de Tooling](dev-docs/user-dd/tooling-guide.md) para reemplazar los placeholders de `package.json` y
   alinear linters/formatters multi-lenguaje.
4. **DocumentaciÃ³n viva** â†’ completa `dev-docs/context.md`, `dev-docs/plan.md` y `dev-docs/task.md` con las decisiones de tu
   producto.

> ğŸ“„ Consulta `dev-docs/user-dd/consumer-checklist.md` para una lista detallada y marcable de responsabilidades.

## âœ… ValidaciÃ³n post-adaptaciÃ³n

Cuando todos los placeholders hayan sido reemplazados, ejecuta una Ãºltima pasada de calidad:

1. Corre lint, tests y type-check con los comandos reales de tu stack (no dejes los ejemplos sin verificar).
2. Confirma que los servicios ficticios (hasher, dispatcher, entrypoint) fueron sustituidos y documentados en `dev-docs/context.md`.
3. Sincroniza README, `dev-docs/plan.md` y `dev-docs/task.md` para que reflejen los comandos y responsables actuales.

> ğŸ“„ Usa la [GuÃ­a de ValidaciÃ³n Post-AdaptaciÃ³n](dev-docs/user-dd/post-adaptation-validation.md) para seguir un checklist completo y registrar hallazgos.

## ğŸ§° Personaliza scripts y linters

Los scripts incluidos en `package.json` apuntan a `src/index.ts`, `dist/index.js` y `scripts/seed.ts`, archivos stub que mantienen
los comandos funcionando desde el primer dÃ­a. Cuando definas tu entry point real, personaliza esos archivos o actualiza los scripts
para apuntar a tu implementaciÃ³n definitiva. Sigue las pautas de `dev-docs/user-dd/tooling-guide.md` para ajustar los comandos `dev`,
`start`, `seed`, `lint`, `format` y `type-check`, asÃ­ como para extender `lint-staged` si trabajas con mÃºltiples lenguajes.

## ğŸ§ª Suites opcionales multi-lenguaje

- `tests/setup/setup_script.test.sh` es el harness oficial del setup interactivo. Corre `npm run test:setup` o `make test:setup` para validar las tres rutas sin tocar tu Ã¡rbol local; el script usa `SETUP_SH_SKIP_INSTALLS=true` para evitar instalaciones reales en entornos CI.
- `tests/integration/test_setup_script.sh` demuestra cÃ³mo validar assets de las plantillas desde Bash. EjecÃºtalo manualmente o  expÃ³n un script (`npm run test:templates`) si quieres integrarlo al pipeline.
- `tests/unit/python/` contiene ejemplos de Pytest para el value object `Email`. Son ilustrativos y no forman parte del comando  `npm test`; habilÃ­talos creando un script propio (`npm run test:py`) o desde tu `Makefile` si tu stack final usa Python. Para  ejecutarlos directamente basta con instalar tus dependencias (`pip install -r requirements.txt` o equivalente) y correr  `pytest tests/unit/python`. Si no vas a mantener una suite en Python, documenta la decisiÃ³n en `dev-docs/context.md` y borra  la carpeta para evitar ruido en tu pipeline.

## ğŸ§± Plantillas de dominio y eventos

- Los value objects (`Email`, `Password`) usan constantes exportadas (regex, dominios bloqueados, longitud mÃ­nima) para que
  puedas sustituir reglas desde un Ãºnico punto sin tocar la lÃ³gica interna.
- El aggregate `User` sÃ³lo modela operaciones bÃ¡sicas y acumula eventos en memoria; la responsabilidad de despacharlos recae en
  tu capa de aplicaciÃ³n a travÃ©s de un `DomainEventDispatcher` propio.
- Sigue el patrÃ³n `save â†’ publish â†’ clear` para evitar publicar eventos que no llegaron a persistirse.
- El bounded context **Identity & Access** ya estÃ¡ descrito en [`dev-docs/domain/ubiquitous-language.md`](dev-docs/domain/ubiquitous-language.md);
  Ãºsalo como blueprint y duplica la plantilla incluida al aÃ±adir nuevos contextos.

> ğŸ“„ Consulta `dev-docs/domain/domain-integration-points.md` para detalles y un checklist de implementaciÃ³n.

## ğŸ› ï¸ Comandos Principales

```bash
# Desarrollo
make dev              # Iniciar entorno de desarrollo
make logs             # Ver logs de la app
make shell            # Abrir shell en container

# Testing
make test             # Ejecutar todos los tests
make test-watch       # Tests en modo watch
make test-coverage    # Tests con coverage

# Database
make migrate          # Ejecutar migraciones
make migrate-down     # Rollback Ãºltima migraciÃ³n
make seed             # Seed development data
make db-shell         # PostgreSQL shell

# Quality
make lint             # Ejecutar linter
make format           # Formatear cÃ³digo
make validate         # Validar arquitectura

# Cleanup
make clean            # Limpiar containers
make reset            # Reset completo (clean + up + migrate + seed)
```

---

## ğŸ“š DocumentaciÃ³n completa

Toda la documentaciÃ³n extendida estÃ¡ organizada en `dev-docs/`:

- **[dev-docs/context.md](dev-docs/context.md)**: VisiÃ³n general del proyecto
- **[dev-docs/plan.md](dev-docs/plan.md)**: Roadmap y milestones
- **[dev-docs/domain/ubiquitous-language.md](dev-docs/domain/ubiquitous-language.md)**: Glosario del dominio
- **[dev-docs/user-dd/consumer-checklist.md](dev-docs/user-dd/consumer-checklist.md)**: Checklist post-clonado para equipos que adopten el kit

**Informes de AuditorÃ­a**:
* [AUDITORIA_SETUP_SH.md](AUDITORIA_SETUP_SH.md) â†’ AnÃ¡lisis profundo del script de setup
* [AUDITORIA_TDD_DDD.md](AUDITORIA_TDD_DDD.md) â†’ EvaluaciÃ³n exhaustiva de capacidades TDD/DDD
* [SECURITY_AUDIT_REPORT.md](SECURITY_AUDIT_REPORT.md) â†’ AuditorÃ­a de seguridad completa

---

## ğŸ›¡ï¸ RemediaciÃ³n del setup interactivo

El informe [`AUDITORIA_SETUP_SH.md`](document/informes_CC/AUDITORIA_SETUP_SH.md) detectÃ³ un bloqueo crÃ­tico en la opciÃ³n Python,
19 vulnerabilidades moderadas en la plantilla TypeScript y varios riesgos de usabilidad. Antes de reutilizar `scripts/setup.sh`
en un proyecto real, sigue el [plan de ejecuciÃ³n](dev-docs/setup/setup-sh-remediation-plan.md) que prioriza:

1. **Correcciones crÃ­ticas** (dependencias Python/TypeScript y manejo de errores de `pip`).
2. **Mejoras de usabilidad** (confirmaciÃ³n de sobrescritura, validaciÃ³n de prerequisitos y limpieza de templates).
3. **Hardening opcional** (tests del script, flags verbosos y guardas para `docker-compose`).

> **Estado actual**: âœ… **Fases A y B completadas**. De la **Fase C** ya estÃ¡n operativos el harness Bash (`tests/setup/setup_script.test.sh`, accesible vÃ­a `npm run test:setup`/`make test:setup`) y la integridad de metadatos (`utc_timestamp` + advertencia cuando falta `docker-compose.dev.yml`). La mejora de observabilidad (`--verbose`/`--no-color`) quedÃ³ documentada como **opcional** para que cada consumidor decida si la incorpora.

> ğŸ“¦ DespuÃ©s de cada ejecuciÃ³n, decide quÃ© hacer con `templates/` directamente desde el prompt final; si prefieres evitar preguntas en entornos automatizados, invoca el script con `--force`.

> ğŸ§ª En pipelines sin acceso a npm/PyPI puedes ejecutar `SETUP_SH_SKIP_INSTALLS=true ./scripts/setup.sh` para saltar `npm install`/`pip install` (el harness usa esa variable por defecto) y aun asÃ­ validar el resto del flujo.

Documenta quÃ© fases aplicaste en `dev-docs/task.md` antes de continuar con las tareas principales del roadmap.

## ğŸ—„ï¸ Blueprint de base de datos y migraciones

Aunque el starkit no provisiona una base de datos real, TASK-003 exige que cada equipo defina su propia estrategia de
persistencia. Consulta [`dev-docs/infrastructure/database-blueprint.md`](dev-docs/infrastructure/database-blueprint.md)
para seguir una guÃ­a agnÃ³stica que cubre:

- Servicios recomendados en `docker-compose.dev.yml` (ejemplo con Postgres, adaptable a otros motores).
- Archivos esperados (`.env.example`, `db/migrations/`, seeds) y su relaciÃ³n con `package.json`/`Makefile`.
- Minitareas, revisiones y comandos de testing que puedes usar para adaptar el kit sin aÃ±adir dependencias
  obligatorias.

Completa la checklist del blueprint y actualiza `dev-docs/task.md` cuando definas tu stack real para que el resto del
equipo conozca el estado de TASK-003.

## ğŸ—ï¸ Architecture Decision Records (ADRs)

Este proyecto utiliza **Architecture Decision Records (ADRs)** para documentar decisiones arquitectÃ³nicas importantes.

### **Â¿CuÃ¡ndo se requiere un ADR?**

Consulte `dev-docs/ADR/ADR_DECISION_MATRIX.md` para determinar si una decisiÃ³n requiere ADR:

**âœ… ADR Requerido para:**
- Cambios en el stack tecnolÃ³gico (frameworks, bases de datos)
- Decisiones de arquitectura del sistema (microservicios, patrones)
- Cambios en infraestructura (despliegue, CI/CD)
- Decisiones de seguridad (autenticaciÃ³n, encriptaciÃ³n)

**âŒ ADR NO requerido para:**
- Detalles de implementaciÃ³n (nombres de variables, estilo de cÃ³digo)
- Refactors menores (mÃ©todos de extracciÃ³n, renombrado)
- Casos de prueba (quÃ© tests escribir)

### **Workflow de ADRs**

```bash
# Antes de decisiones arquitectÃ³nicas:
1. Consultar ADR_DECISION_MATRIX.md
2. Buscar ADRs existentes: find dev-docs/ADR -name "ADR-*.md"
3. Crear ADR si es requerido: usar ADR_TEMPLATE_AND_GUIDE.md
4. Referenciar ADR en implementaciÃ³n: commits, cÃ³digo

# Herramientas ADR:
./scripts/adr-helper.sh help
```

### **DocumentaciÃ³n ADR**

- **Template**: `dev-docs/ADR/ADR_TEMPLATE_AND_GUIDE.md`
- **Matriz Decisiones**: `dev-docs/ADR/ADR_DECISION_MATRIX.md`
- **Workflow**: `dev-docs/ADR/ADR_WORKFLOW.md`
- **Ãndice**: `dev-docs/ADR/ADR_INDEX.md`

### **Herramientas ADR**

```bash
# GestiÃ³n de ADRs:
./scripts/adr-helper.sh help

# BÃºsqueda y referencias:
./scripts/adr-reference-checker.sh help
./scripts/adr-reference-checker.sh list
./scripts/adr-reference-checker.sh check-keyword <termino>

# Para agentes IA:
./scripts/adr-reference-checker.sh suggest "tarea comÃºn"
./scripts/adr-reference-checker.sh current-task
```

### **ADRs Activos**

**ADR-001**: Sistema de IntegraciÃ³n ADR âœ… *Aceptado (17-Nov-2025)*
- Documenta la creaciÃ³n del sistema ADR
- Establece workflow para decisiones arquitectÃ³nicas
- Integra herramientas para agentes EJECUTOR/VALIDADOR

**Ver ADR completo**: `dev-docs/ADR/ADR-001-adr-integration-system.md`

### **Para Agentes IA**

**Workflow para EJECUTOR**:
1. Verificar si ADR es requerido: `./scripts/adr-helper.sh check-required`
2. Buscar ADRs existentes: `./scripts/adr-reference-checker.sh list`
3. Crear ADR si necesario: `./scripts/adr-helper.sh create`
4. Referenciar ADR en implementaciÃ³n: commits, cÃ³digo, PRs

**Workflow para VALIDADOR**:
1. Validar ADRs requeridos: `./scripts/adr-helper.sh validate`
2. Verificar referencias cruzadas: `./scripts/adr-reference-checker.sh`
3. Validar formato: `./scripts/adr-helper.sh validate ADR-XXX.md`
4. Actualizar Ã­ndice: Verificar `dev-docs/ADR/ADR_INDEX.md`

## ğŸ§­ Post-clone Checklist

Este repositorio es un **starkit agnÃ³stico**: incluye ejemplos, no una aplicaciÃ³n completa. DespuÃ©s de clonar, sigue estos pasos
para dejarlo operativo en tu contexto:

1. **Entry point real** â†’ crea el archivo de arranque de tu servicio (`src/index.ts`, `main.py`, etc.) y actualiza los scripts
   (`package.json`, `Makefile`, `docker-compose`) para apuntar a Ã©l.
2. **Dependencias implÃ­citas** â†’ importa manualmente mÃ³dulos como `crypto` y reemplaza los helpers ficticios (`hashed_${plainPassword}`,
   event dispatcher en memoria) por servicios reales.
3. **Tooling** â†’ decide tu stack de lint/test (ESLint, Pytest, Go test, etc.) y actualiza `lint-staged`, hooks y pipelines segÃºn
   corresponda. Consulta la [GuÃ­a de Tooling](dev-docs/user-dd/tooling-guide.md) para reemplazar los placeholders de `package.json` y
   alinear linters/formatters multi-lenguaje.
4. **DocumentaciÃ³n viva** â†’ completa `dev-docs/context.md`, `dev-docs/plan.md` y `dev-docs/task.md` con las decisiones de tu
   producto.

> ğŸ“„ Consulta `dev-docs/user-dd/consumer-checklist.md` para una lista detallada y marcable de responsabilidades.

## âœ… ValidaciÃ³n post-adaptaciÃ³n

Cuando todos los placeholders hayan sido reemplazados, ejecuta una Ãºltima pasada de calidad:

1. Corre lint, tests y type-check con los comandos reales de tu stack (no dejes los ejemplos sin verificar).
2. Confirma que los servicios ficticios (hasher, dispatcher, entrypoint) fueron sustituidos y documentados en `dev-docs/context.md`.
3. Sincroniza README, `dev-docs/plan.md` y `dev-docs/task.md` para que reflejen los comandos y responsables actuales.

> ğŸ“„ Usa la [GuÃ­a de ValidaciÃ³n Post-AdaptaciÃ³n](dev-docs/user-dd/post-adaptation-validation.md) para seguir un checklist completo y registrar hallazgos.

## ğŸ§° Personaliza scripts y linters

Los scripts incluidos en `package.json` apuntan a `src/index.ts`, `dist/index.js` y `scripts/seed.ts`, archivos stub que mantienen
los comandos funcionando desde el primer dÃ­a. Cuando definas tu entry point real, personaliza esos archivos o actualiza los scripts
para apuntar a tu implementaciÃ³n definitiva. Sigue las pautas de `dev-docs/user-dd/tooling-guide.md` para ajustar los comandos `dev`,
`start`, `seed`, `lint`, `format` y `type-check`, asÃ­ como para extender `lint-staged` si trabajas con mÃºltiples lenguajes.

## ğŸ§ª Suites opcionales multi-lenguaje

- `tests/setup/setup_script.test.sh` es el harness oficial del setup interactivo. Corre `npm run test:setup` o `make test:setup` para validar las tres rutas sin tocar tu Ã¡rbol local; el script usa `SETUP_SH_SKIP_INSTALLS=true` para evitar instalaciones reales en entornos CI.
- `tests/integration/test_setup_script.sh` demuestra cÃ³mo validar assets de las plantillas desde Bash. EjecÃºtalo manualmente o  expÃ³n un script (`npm run test:templates`) si quieres integrarlo al pipeline.
- `tests/unit/python/` contiene ejemplos de Pytest para el value object `Email`. Son ilustrativos y no forman parte del comando  `npm test`; habilÃ­talos creando un script propio (`npm run test:py`) o desde tu `Makefile` si tu stack final usa Python. Para  ejecutarlos directamente basta con instalar tus dependencias (`pip install -r requirements.txt` o equivalente) y correr  `pytest tests/unit/python`. Si no vas a mantener una suite en Python, documenta la decisiÃ³n en `dev-docs/context.md` y borra  la carpeta para evitar ruido en tu pipeline.

## ğŸ§± Plantillas de dominio y eventos

- Los value objects (`Email`, `Password`) usan constantes exportadas (regex, dominios bloqueados, longitud mÃ­nima) para que
  puedas sustituir reglas desde un Ãºnico punto sin tocar la lÃ³gica interna.
- El aggregate `User` sÃ³lo modela operaciones bÃ¡sicas y acumula eventos en memoria; la responsabilidad de despacharlos recae en
  tu capa de aplicaciÃ³n a travÃ©s de un `DomainEventDispatcher` propio.
- Sigue el patrÃ³n `save â†’ publish â†’ clear` para evitar publicar eventos que no llegaron a persistirse.
- El bounded context **Identity & Access** ya estÃ¡ descrito en [`dev-docs/domain/ubiquitous-language.md`](dev-docs/domain/ubiquitous-language.md);
  Ãºsalo como blueprint y duplica la plantilla incluida al aÃ±adir nuevos contextos.

> ğŸ“„ Consulta `dev-docs/domain/domain-integration-points.md` para detalles y un checklist de implementaciÃ³n.

## ğŸ› ï¸ Comandos Principales

```bash
# Setup inicial
./scripts/setup.sh

# Desarrollo
make dev              # Iniciar entorno de desarrollo
make test             # Ejecutar todos los tests
make validate         # Validar arquitectura

# Calidad
make lint             # Ejecutar linter
make format           # Formatear cÃ³digo
```

---

## ğŸ™ Agradecimientos

Este kit no serÃ­a posible sin las ideas, principios y contribuciones intelectuales de:

* **Robert C. Martin** â€” Clean Architecture, SOLID
* **Eric Evans** â€” Domain-Driven Design
* **Martin Fowler** â€” Refactoring, Patterns of Enterprise Application Architecture
* **Kent Beck** â€” Test-Driven Development
* **Michael Nygard** â€” Release It! (resilience patterns)
* **Google SRE Team** â€” Observability, SLOs
* **OWASP Foundation** â€” Seguridad de aplicaciones web

**InvestigaciÃ³n AcadÃ©mica Integrada**:
* Chen et al (2024) â€” "Evaluating Large Language Models Trained on Code"
* Liu et al (2024) â€” "Lost in the Middle: How Language Models Use Long Contexts"

---

## ğŸ“œ Licencia

MIT â€” Ãºsalo libremente para cualquier proyecto.
